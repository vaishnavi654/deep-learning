{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSZYiivQegFi",
        "colab_type": "text"
      },
      "source": [
        "# Installing dependencies & setting up a GPU environment\n",
        "\n",
        "\n",
        "The version of tensorflow is 2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXh6DjUTcIe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5bde303f-8d79-477d-f50a-9c450c169584"
      },
      "source": [
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.6/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeAxN5O2ev1G",
        "colab_type": "text"
      },
      "source": [
        "# Importing the libraries\n",
        "Here we have imported the tensorflow libraries.\n",
        "Also imported the IMDB datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD-b7BnIdNaf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uong37CHe_Fy",
        "colab_type": "text"
      },
      "source": [
        "This shows the version of tensorflow we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ErvTUMeS5P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06b9f0d6-7e88-4424-99ec-74c6663f93ae"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvuWi9xmspcA",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing\n",
        "As we preprocess text here so data preprocessing is different if compared to artificial neural network and convolutional neural network.\n",
        "So, main thing we have to do is to pad all the sequences to be same, because reviews don't have the same length.\n",
        "These things has to be done to make all the input text having same length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqg_Jn8UtM1V",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n",
        "Setting up the dataset parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD3C_KStubL4",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n",
        "*   number_of_words we want from the IMDB dataset.\n",
        "*   max_len is total length of sequence after the padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tjjufzledIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_words = 20000\n",
        "max_len = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU5xtYgbvUq1",
        "colab_type": "text"
      },
      "source": [
        "# Loading IMDB dataset\n",
        "*   (x_train, y_train) in train set \n",
        "*   (x_test, y_test) in test set.\n",
        "_________________________________________\n",
        "X_train are input reviews.\n",
        "y_train are labels saying that reviews are positive or negative.\n",
        "_________________________________________\n",
        "X_test contains all input reviews.\n",
        "y_test label positive or negative of these reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyMqp83NwZa1",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n",
        "we are loading data from IMDB which are actually taken from keras dataset.\n",
        "And the maximum number of words are 20000, to make training process easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m50RFZBt-2sJ",
        "colab_type": "text"
      },
      "source": [
        "________________________________________________________________________________\n",
        "load_data is the method to load data from the datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmfkedW0ttTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=number_of_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0SdamztSfTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ff2646e5-7113-4dfc-d29e-a16aa11171d4"
      },
      "source": [
        "print('---review---')\n",
        "print(X_train[6])\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vYVqwVESyu9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPci-UjGSzmI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "65707661-0653-40d7-8e5d-3354c04bd3a8"
      },
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in X_train[6]])\n",
        "print('---label---')\n",
        "print(y_train[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---review with words---\n",
            "['the', 'boiled', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'murdering', 'naschy', 'br', 'villain', 'council', 'suggestion', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'echoed', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "---label---\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvmDsXZSyF7O",
        "colab_type": "text"
      },
      "source": [
        "# Padding all sequences to be the same length\n",
        "If the sequence is less than n words (where n<100), then after 'n' there would be bad tokens upto 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARCGztwQzol3",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGBZFY9Kz24h",
        "colab_type": "text"
      },
      "source": [
        "This pad_sequence() function takes all the reviews in X_train,therefore the different length & maximum length of padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBPWdfGM_a-_",
        "colab_type": "text"
      },
      "source": [
        "pad_sequence() function is under sequence submodule which, and sequence submodule is under preprocessing module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QzWSYE1wP9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgurkOtdy7bm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUBA6uK3FS8i",
        "colab_type": "text"
      },
      "source": [
        "**Setting up embedding layer parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Ba4bbQFc9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50dacffd-d136-45d6-cc1e-39402209e767"
      },
      "source": [
        "vocal_size = number_of_words\n",
        "vocal_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6DFpsKPK_Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed_size = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C02HTIk0lA0d",
        "colab_type": "text"
      },
      "source": [
        "# Building a recurrent neural network\n",
        "**Defining the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RykCk6slRpX",
        "colab_type": "text"
      },
      "source": [
        "we have used sequential class here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va4sGNu3zGxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEs84qm_lliV",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n",
        "Now we are adding layers to the model\n",
        "_________________________________________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ou--RfEflWdh",
        "colab_type": "text"
      },
      "source": [
        "**Adding the embeding layer**\n",
        "\n",
        "we are using embeding layer, it used to create a word vector representation of the words.\n",
        "\n",
        "We are going to use the word vectors in a large matrix & this large matrix will be a matrix where each row corresponds to a word and the columns are actually encoding the word with what we call a representation of the word in the dataset vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyC9tLo-9Jms",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n",
        "*  input_dim=input dimension which is number_of_words.\n",
        "*  output_dim=output dimension which is number of column which are to be embedded each word to its large representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3-jq_XTlMmJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Embedding(vocal_size, embed_size, input_shape=(X_train.shape[1],)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjLL27C19t0f",
        "colab_type": "text"
      },
      "source": [
        "# Adding the LSTM layer\n",
        "\n",
        "\n",
        "*   unit=128(these are LSTM cells inside the LSTM layer)\n",
        "*   activation=tanh(hyperbolic tanjent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYaU4I1b9F0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.LSTM(units=128, activation='tanh'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhYxczr-ANEH",
        "colab_type": "text"
      },
      "source": [
        "# Add output layer\n",
        "*  units = 1\n",
        "*  activation=sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B3Uxf-E-LwB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2T3wKhhAn2J",
        "colab_type": "text"
      },
      "source": [
        "# Compiling the model\n",
        "________________________________________________________________________________\n",
        "RMSprop optimizer = RmsProp is an optimizer that utilizes the magnitude of recent gradients to normalize the gradients. We always keep a moving average over the root mean squared (hence Rms) gradients, by which we divide the current gradient.\n",
        "________________________________________________________________________________\n",
        "binary_crossentropy = Binary crossentropy\n",
        "The loss function binary crossentropy is used on yes/no decisions, e.g., multi-label classification. The loss tells you how wrong your modelâ€™s predictions are. For instance, in multi-label problems, where an example can belong to multiple classes at the same time, the model tries to decide for each class whether the example belongs to that class or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gFxTxdQAdxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVKXymg-Ck99",
        "colab_type": "text"
      },
      "source": [
        "model.summary() will give the structural summary of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEg7HuqqCOgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "ee09d407-0e05-438e-f73f-7e2ee41a3b7c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3Kho951C6zB",
        "colab_type": "text"
      },
      "source": [
        "# Training the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cXEWHt7DKUZ",
        "colab_type": "text"
      },
      "source": [
        "_________________________________________\n",
        "batch_size meaning we are going to feed the neural network with different batched each one having 128 input reviews, all padded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T9QYVqECi-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a51bc399-0646-4c40-8c66-e676daa70bfc"
      },
      "source": [
        "model.fit(X_train, y_train, epochs=3, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "196/196 [==============================] - 77s 392ms/step - loss: 0.4616 - accuracy: 0.7828\n",
            "Epoch 2/3\n",
            "196/196 [==============================] - 77s 392ms/step - loss: 0.2891 - accuracy: 0.8826\n",
            "Epoch 3/3\n",
            "196/196 [==============================] - 78s 398ms/step - loss: 0.2340 - accuracy: 0.9098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff2c3386c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kQlYk6uF4yV",
        "colab_type": "text"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwvK0mRGF8JS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2d5106c-345d-45ba-ae7e-e8beed5edc94"
      },
      "source": [
        "test_loss, test_acurracy = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 27s 35ms/step - loss: 0.3512 - accuracy: 0.8529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRTRAtMoJJ1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a55e1fc8-310c-4b7f-b621-16615d5bb663"
      },
      "source": [
        "test_acurracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8528800010681152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qujMniT-SYY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}